## Default values for charts.
## This is a YAML-formatted file.
## Declare variables to be passed into your templates.

## @param global karmada global config
global:
  ## @param global.imageRegistry Global Docker image registry
  imageRegistry: ""

## @param installMode "host" and "agent" are provided
## "host" means install karmada in the control-cluster
## "agent" means install agent client in the member cluster
## "component" means install selected components in the control-cluster
installMode: "host"

## @param clusterDomain default domain for karmada
clusterDomain: k0s.resolvemy.host

## @param components component list
components: [
    "schedulerEstimator",
    "descheduler",
    "search"
  ]

## pre-install job config
preInstallJob:
  ## @param preInstallJob.initContainerImage image of the pre-install job's initContainer
  initContainerImage: cfssl/cfssl
  ## @param preInstallJob.preInstallContainerImage image of the pre-install job
  preInstallContainerImage: bitnami/kubectl:latest

## post-install job config
postInstallJob:
  ## @param postInstallJob.postInstallContainerImage image of the post-install job
  postInstallContainerImage: bitnami/kubectl:latest

## post-delete job config
postDeleteJob:
  ## @param postDeleteJob.postDeleteContainerImage image of the post-delete job
  postDeleteContainerImage: bitnami/kubectl:latest

## karmada certificate config
certs:
  ## @param certs.mode "auto" and "custom" are provided
  ## "auto" means auto generate certificate
  ## "custom" means use user certificate
  mode: auto
  auto:
    ## @param certs.auto.expiry expiry of the certificate
    expiry: 43800h
    ## @param certs.auto.hosts hosts of the certificate
    hosts: [
      "kubernetes.default.svc",
      "*.etcd.{{ .Release.Namespace }}.svc.{{ .Values.clusterDomain }}",
      "*.{{ .Release.Namespace }}.svc.{{ .Values.clusterDomain }}",
      "*.{{ .Release.Namespace }}.svc",
      "localhost",
      "127.0.0.1"
    ]
  custom:
    ## @param certs.custom.caCrt ca of the certificate
    caCrt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param certs.custom.crt crt of the certificate
    crt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param certs.custom.key key of the certificate
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END RSA PRIVATE KEY-----
    ## @param certs.custom.frontProxyCaCrt ca of the front proxy certificate
    frontProxyCaCrt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param certs.custom.frontProxyCrt crt of the front proxy certificate
    frontProxyCrt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param certs.custom.frontProxyKey key of the front proxy certificate
    frontProxyKey: |
      -----BEGIN RSA PRIVATE KEY-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END RSA PRIVATE KEY-----

## scheduler config
scheduler:
  ## @param scheduler.labels labels of the schedeler deployment
  labels:
    app: karmada-scheduler
  ## @param scheduler.replicaCount target replicas of the scheduler
  replicaCount: 1
  ## @param scheduler.podAnnotations annotaions of the scheduler pods
  podAnnotations: {}
  ## @param scheduler.podLabels labels of the scheduler pods
  podLabels: {}
  ## @param scheduler.imagePullSecrets image pull secret of the scheduler
  imagePullSecrets: []
  ## @param image.registry karmada scheduler image registry
  ## @param image.repository karmada scheduler image repository
  ## @param image.tag karmada scheduler image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada scheduler image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-scheduler
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param scheduler.resources resource quota of the scheduler
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param scheduler.nodeSelector node selector of the scheduler
  nodeSelector: {}
  ## @param scheduler.affinity affinity of the scheduler
  affinity: {}
  ## @param scheduler.tolerations tolerations of the scheduler
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param scheduler.strategy strategy of the scheduler
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## webhook config
webhook:
  ## @param webhook.labels labels of the webhook deployment
  labels:
    app: karmada-webhook
  ## @param webhook.replicaCount target replicas
  replicaCount: 1
  ## @param webhook.podAnnotations annotaions of the webhook pods
  podAnnotations: {}
  ## @param webhook.podLabels labels of the webhook pods
  ## @param webhook.imagePullSecrets image pull secret of the webhook
  imagePullSecrets: []
  ## @param image.registry karmada webhook image registry
  ## @param image.repository karmada webhook image repository
  ## @param image.tag karmada webhook image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada webhook image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-webhook
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param webhook.resources resource quota of the webhook
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param webhook.nodeSelector node selector of the webhook
  nodeSelector: {}
  ## @param webhook.affinity affinity of the webhook
  affinity: {}
  ## @param webhook.tolerations tolerations of the webhook
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param webhook.strategy strategy of the webhook
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## controller manager config
controllerManager:
  ## @param controllerManager.labels labels of the karmada-controller-manager deployment
  labels:
    app: karmada-controller-manager
  ## @param controllerManager.replicaCount target replicas of the karmada-controller-manager
  replicaCount: 1
  ## @param controllerManager.podAnnotations annotaions of the karmada-controller-manager pods
  podAnnotations: {}
  ## @param controllerManager.podLabels labels of the karmada-controller-manager pods
  podLabels: {}
  ## @param controllerManager.imagePullSecrets image pull secret of the karmada-controller-manager
  imagePullSecrets: []
  ## @param image.registry karmada controller manager image registry
  ## @param image.repository karmada controller manager image repository
  ## @param image.tag karmada controller manager image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada controller manager image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-controller-manager
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param controllerManager.resources resource quota of the karmada-controller-manager
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param controllerManager.nodeSelector node selector of the karmada-controller-manager
  nodeSelector: {}
  ## @param controllerManager.affinity affinity of the karmada-controller-manager
  affinity: {}
  ## @param controllerManager.tolerations tolerations of the karmada-controller-manager
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param controllerManager.strategy strategy of the controller manager
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## karmada apiserver config
apiServer:
  ## @param apiServer.labels labels of the karmada-apiserver deployment
  labels:
    app: karmada-apiserver
  ## @param apiServer.replicaCount target replicas of the karmada-apiserver
  replicaCount: 1
  ## @param apiServer.podAnnotations annotaions of the karmada-apiserver pods
  podAnnotations: {}
  ## @param apiServer.podLabels labels of the karmada-apiserver pods
  podLabels: {}
  ## @param apiServer.imagePullSecrets image pull secret of the karmada-apiserver
  imagePullSecrets: []
  ## @param image.registry keube-apiserver image registry
  ## @param image.repository keube-apiserver image repository
  ## @param image.tag keube-apiserver image tag (immutable tags are recommended)
  ## @param image.pullPolicy keube-apiserver image pull policy
  ##
  image:
    registry: k8s.gcr.io
    repository: kube-apiserver
    tag: v1.23.6
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param apiServer.resources resource quota of the karmada-apiserver
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param apiServer.hostNetwork
  ## "true" means using hostNetwork
  ## "false" means normal network
  hostNetwork: false
  ## @param apiServer.nodeSelector node selector of the karmada-apiserver
  nodeSelector: {}
  ## @param apiServer.affinity affinity of the karmada-apiserver
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - karmada-apiserver
          topologyKey: kubernetes.io/hostname
  ## @param apiServer.tolerations tolerations of the karmada-apiserver
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param apiServer.serviceType default service type for apiserver
  ## "LoadBalancer" means using LoadBalancer
  ## "ClusterIP" means using ClusterIP
  ## "NodePort" means using NodePort
  serviceType: ClusterIP
  ## @param apiServer.nodePort node port for apiserver service,
  ## will take effect when 'apiServer.serviceType' is 'NodePort'.
  ## If no port is specified, the nodePort will be automatically assigned.
  nodePort: 0
  maxRequestsInflight: 1500
  maxMutatingRequestsInflight: 500
  ## @param apiserver.strategy strategy of the apiserver
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1

## karmada aggregated apiserver config
aggregatedApiServer:
  ## @param aggregatedApiServer.labels labels of the karmada-aggregated-apiserver pods
  labels:
    app: karmada-aggregated-apiserver
  ## @param aggregatedApiServer.replicaCount target replicas of the karmada-aggregated-apiserver
  replicaCount: 1
  ## @param aggregatedApiServer.podAnnotations annotaions of the karmada-aggregated-apiserver pods
  podAnnotations: {}
  ## @param aggregatedApiServer.podLabels labels of the karmada-aggregated-apiserver pods
  podLabels: {}
  ## @param aggregatedApiServer.imagePullSecrets image of the karmada-aggregated-apiserver
  imagePullSecrets: []
  ## @param image.registry karmada aggregatedApiServer image registry
  ## @param image.repository karmada aggregatedApiServer image repository
  ## @param image.tag karmada aggregatedApiServer image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada aggregatedApiServer image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-aggregated-apiserver
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param aggregatedApiServer.resources resource quota of the karmada-aggregated-apiserver
  resources:
    requests:
      cpu: 100m
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param aggregatedApiServer.nodeSelector node selector of the karmada-aggregated-apiserver
  nodeSelector: {}
  ## @param aggregatedApiServer.affinity affinity of the karmada-aggregated-apiserver
  affinity: {}
  ## @param aggregatedApiServer.tolerations tolerations of the karmada-aggregated-apiserver
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param aggregatedApiServer.strategy strategy of the karmada-aggregated-apiserver
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## kubernetes controller manager config
kubeControllerManager:
  ## @param kubeControllerManager.labels labels of the kube-controller-manager deployment
  labels:
    app: kube-controller-manager
  ## @param kubeControllerManager.replicaCount target replicas of the kube-controller-manager
  replicaCount: 1
  ## @param kubeControllerManager.podAnnotations annotaions of the kube-controller-manager pods
  podAnnotations: {}
  ## @param kubeControllerManager.podLabels labels of the kube-controller-manager pods
  podLabels: {}
  ## @param kubeControllerManager.imagePullSecrets image pull secret of the kube-controller-manager
  imagePullSecrets: []
  ## @param image.registry kubeControllerManager image registry
  ## @param image.repository kubeControllerManager image repository
  ## @param image.tag kubeControllerManager image tag (immutable tags are recommended)
  ## @param image.pullPolicy kubeControllerManager image pull policy
  ##
  image:
    registry: k8s.gcr.io
    repository: kube-controller-manager
    tag: v1.23.6
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param kubeControllerManager.resources resource quota of the kube-controller-manager
  resources:
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param kubeControllerManager.nodeSelector node selector of the kube-controller-manager
  nodeSelector: {}
  ## @param kubeControllerManager.affinity affinity of the kube-controller-manager
  affinity: {}
  ## @param kubeControllerManager.tolerations tolerations of the kube-controller-manager
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param kubeControllerManager.strategy strategy of the kube controller manager
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## etcd config
etcd:
  ## @param etcd.mode "external" and "internal" are provided
  ## "external" means use external ectd
  ## "internal" means install a etcd in the cluster
  mode: "internal"
  external:
    ## @param etcd.external.servers servers of etcd
    ## such as "https://192.168.1.1:2379,https://192.168.1.2:2379,https://192.168.1.3:2379"
    servers: ""
    ## @param etcd.external.registryPrefix use to registry prefix of etcd
    registryPrefix: "/registry/karmada"
    certs:
      ## @param etcd.external.certs.caCrt ca of the certificate
      caCrt: |
        -----BEGIN CERTIFICATE-----
        XXXXXXXXXXXXXXXXXXXXXXXXXXX
        -----END CERTIFICATE-----
      ## @param etcd.external.certs.crt crt of the certificate
      crt: |
        -----BEGIN CERTIFICATE-----
        XXXXXXXXXXXXXXXXXXXXXXXXXXX
        -----END CERTIFICATE-----
      ## @param etcd.external.certs.key key of the certificate
      key: |
        -----BEGIN RSA PRIVATE KEY-----
        XXXXXXXXXXXXXXXXXXXXXXXXXXX
        -----END RSA PRIVATE KEY-----
  internal:
    ## @param etcd.internal.replicaCount target replicas
    replicaCount: 1
    ## @param image.registry etcd image registry
    ## @param image.repository etcd image repository
    ## @param image.tag etcd image tag (immutable tags are recommended)
    ## @param image.pullPolicy etcd image pull policy
    ##
    image:
      registry: k8s.gcr.io
      repository: etcd
      tag: "3.5.3-0"
      ## Specify a imagePullPolicy
      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
      ##
      pullPolicy: IfNotPresent
    ## @param etcd.internal.storageType storage type for etcd data
    ## "pvc" means using volumeClaimTemplates
    ## "hostPath" means using hostPath
    storageType: "pvc"
    pvc:
      ## @param etcd.internal.pvc.storageClass storageClass name of PVC
      storageClass: ""
      ## @param etcd.internal.pvc.size size of PVC
      size: 50G
    ## @param etcd.internal.resources
    resources: {}
      # If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      # limits:
      #   cpu: 100m
      #   memory: 128Mi
      # requests:
      #   cpu: 100m
      #   memory: 128Mi

## agent client config
agent:
  ## @param agent.clusterName name of the member cluster
  clusterName: ""
  ## kubeconfig of the karmada
  kubeconfig:
    ## @param agent.kubeconfig.caCrt ca of the certificate
    caCrt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param agent.kubeconfig.crt crt of the certificate
    crt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param agent.kubeconfig.key key of the certificate
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END RSA PRIVATE KEY-----
    ## @param agent.kubeconfig.server apiserver of the karmada
    server: ""
  ## @param agent.labels labels of the agent deployment
  labels:
    app: karmada-agent
  ## @param agent.replicaCount target replicas
  replicaCount: 1
  ## @param agent.podAnnotations annotaions of the agent pods
  podAnnotations: {}
  ## @param agent.podLabels labels of the agent pods
  podLabels: {}
  ## @param agent.imagePullSecrets image pull secret of the agent
  imagePullSecrets: []
  ## @param image.registry karmada agent image registry
  ## @param image.repository karmada agent image repository
  ## @param image.tag karmada agent image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada agent image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-agent
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param agent.resources
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param agent.nodeSelector node selector of the agent
  nodeSelector: {}
  ## @param agent.affinity affinity of the agent
  affinity: {}
  ## @param agent.tolerations tolerations of the agent
  tolerations: {}
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param agent.strategy strategy of the agent
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## karmada scheduler estimator
schedulerEstimator:
  ## schedulerEstimator.clusterName the name of the member cluster
  clusterName: ""
  ## kubeconfig of the member cluster
  kubeconfig:
    ## @param schedulerEstimator.kubeconfig.caCrt ca of the certificate
    caCrt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param schedulerEstimator.kubeconfig.crt crt of the certificate
    crt: |
      -----BEGIN CERTIFICATE-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END CERTIFICATE-----
    ## @param schedulerEstimator.kubeconfig.key key of the certificate
    key: |
      -----BEGIN RSA PRIVATE KEY-----
      XXXXXXXXXXXXXXXXXXXXXXXXXXX
      -----END RSA PRIVATE KEY-----
    ## @param schedulerEstimator.kubeconfig.server apiserver of the member cluster
    server: ""
  ## @param schedulerEstimator.labels labels of the scheduler-estimator deployment
  labels: {}
  ## @param schedulerEstimator.replicaCount target replicas
  replicaCount: 1
  ## @param schedulerEstimator.podAnnotations annotaions of the scheduler-estimator pods
  podAnnotations: {}
  ## @param schedulerEstimator.podLabels labels of the scheduler-estimator pods
  podLabels: {}
  ## @param schedulerEstimator.imagePullSecrets image pull secret of the scheduler-estimator
  imagePullSecrets: []
  ## @param image.registry karmada schedulerEstimator image registry
  ## @param image.repository karmada schedulerEstimator image repository
  ## @param image.tag karmada schedulerEstimator image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada schedulerEstimator image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-scheduler-estimator
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param schedulerEstimator.resources resource quota of the scheduler-estimator
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param schedulerEstimator.nodeSelector node selector of the scheduler-estimator
  nodeSelector: {}
  ## @param schedulerEstimator.affinity affinity of the scheduler-estimator
  affinity: {}
  ## @param schedulerEstimator.tolerations tolerations of the scheduler-estimator
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param schedulerEstimator.strategy strategy of the scheduler-estimator
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## descheduler config
descheduler:
  ## @param descheduler.labels labels of the descheduler deployment
  labels:
    app: karmada-descheduler
  ## @param descheduler.replicaCount target replicas of the descheduler
  replicaCount: 2
  ## @param descheduler.podAnnotations annotaions of the descheduler pods
  podAnnotations: {}
  ## @param descheduler.podLabels labels of the descheduler pods
  podLabels: {}
  ## @param descheduler.imagePullSecrets image pull secret of the descheduler
  imagePullSecrets: []
  ## @param image.registry karmada descheduler image registry
  ## @param image.repository karmada descheduler image repository
  ## @param image.tag karmada descheduler image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada descheduler image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-descheduler
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param descheduler.resources resource quota of the descheduler
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  ## @param descheduler.nodeSelector node selector of the descheduler
  nodeSelector: {}
  ## @param descheduler.affinity affinity of the descheduler
  affinity: {}
  ## @param descheduler.tolerations tolerations of the descheduler
  tolerations: []
    # - key: node-role.kubernetes.io/master
    #   operator: Exists
  ## @param descheduler.strategy strategy of the descheduler
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%

## karmada-search config
search:
  ## @param search.labels labels of the search deployment
  labels:
    app: karmada-search
    apiserver: "true"
  ## @param search.replicaCount target replicas
  replicaCount: 2
  ## @param search.podAnnotations annotaions of the search pods
  podAnnotations: {}
  ## @param search.podLabels labels of the search pods
  podLabels: {}
  ## @param search.imagePullSecrets image pull secret of the search
  imagePullSecrets: []
  ## @param image.registry karmada search image registry
  ## @param image.repository karmada search image repository
  ## @param image.tag karmada search image tag (immutable tags are recommended)
  ## @param image.pullPolicy karmada search image pull policy
  ##
  image:
    registry: swr.ap-southeast-1.myhuaweicloud.com
    repository: karmada/karmada-search
    tag: latest
    ## Specify a imagePullPolicy
    ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'
    ##
    pullPolicy: IfNotPresent
  ## @param search.resources resource quota of the search
  resources: {}
    # If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
  #   memory: 128Mi
  ## @param search.nodeSelector node selector of the search
  nodeSelector: {}
  ## @param search.affinity affinity of the search
  affinity: {}
  ## @param search.tolerations tolerations of the search
  tolerations: []
    # - key: node-role.kubernetes.io/master
  #   operator: Exists
  ## @param search.strategy strategy of the search
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 50%


liqo:
  # Default values for liqo.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.

  # -- Images' tag to select a development version of liqo instead of a release
  tag: ""
  # -- The pullPolicy for liqo pods
  pullPolicy: "IfNotPresent"

  enabled: false

  apiServer:
    # -- The address that must be used to contact your API server, it needs to be reachable from the clusters that you will peer with (defaults to your master IP)
    address: 10.1.1.40:6443
    # -- Indicates that the API Server is exposing a certificate issued by a trusted Certification Authority
    trustedCA: false

  controllerManager:
    # -- The number of controller-manager instances to run, which can be increased for active/passive high availability.
    replicas: 1
    pod:
      # -- controller-manager pod annotations
      annotations: {}
      # -- controller-manager pod labels
      labels: {}
      # -- controller-manager pod extra arguments
      extraArgs: []
    # -- controller-manager image repository
    imageName: "liqo/liqo-controller-manager"

    config:
      # -- It defines the percentage of available cluster resources that you are willing to share with foreign clusters.
      resourceSharingPercentage: 70

  route:
    pod:
      # -- route pod annotations
      annotations: {}
      # -- route pod labels
      labels: {}
      # -- route pod extra arguments
      extraArgs: []
    # -- route image repository
    imageName: "liqo/liqonet"

  gateway:
    # -- The number of gateway instances to run.
    # The gateway component supports active/passive high availability.
    # Make sure that there are enough nodes to accommodate the replicas, because being the instances in host network no more
    # than one replica can be scheduled on a given node.
    replicas: 1

    pod:
      # -- gateway pod annotations
      annotations: {}
      # -- gateway pod labels
      labels: {}
      # -- gateway pod extra arguments
      extraArgs: []

    # -- gateway image repository
    imageName: "liqo/liqonet"

    service:
      # -- If you plan to use liqo over the Internet, consider to change this field to "LoadBalancer".
      # Instead, if your nodes are directly reachable from the cluster you are peering to, you may change it to "NodePort".
      type: "LoadBalancer"
      annotations: {}
    
    config:
      # -- port used by the vpn tunnel.
      listeningPort: 5871

  networkManager:
    pod:
      # -- networkManager pod annotations
      annotations: {}
      # -- networkManager pod labels
      labels: {}
      # -- networkManager pod extra arguments
      extraArgs: []

    # -- networkManager image repository
    imageName: liqo/liqonet

    config:
      # -- The subnet used by the cluster for the pods, in CIDR notation
      podCIDR: 192.168.250.0/24
      # -- The subnet used by the cluster for the services, in CIDR notation
      serviceCIDR: 10.6.8.0/24
      # -- Usually the IPs used for the pods in k8s clusters belong to private subnets.
      # In order to prevent IP conflicting between locally used private subnets in your infrastructure and private subnets belonging to remote clusters
      # you need tell liqo the subnets used in your cluster. E.g if your cluster nodes belong to the 192.168.2.0/24 subnet then
      # you should add that subnet to the reservedSubnets. PodCIDR and serviceCIDR used in the local cluster are automatically added to the reserved list.
      reservedSubnets: []
      # -- Set of additional network pools.
      # Network pools are used to map a cluster network into another one in order to prevent conflicts.
      # Default set of network pools is: [10.0.0.0/8, 192.168.0.0/16, 172.16.0.0/12]
      additionalPools: []

  crdReplicator:
    pod:
      # -- crdReplicator pod annotations
      annotations: {}
      # -- crdReplicator pod labels
      labels: {}
      # -- crdReplicator pod extra arguments
      extraArgs: []
    # -- crdReplicator image repository
    imageName: "liqo/crd-replicator"

  discovery:
    pod:
      # -- discovery pod annotations
      annotations: {}
      # -- discovery pod labels
      labels: {}
      # -- discovery pod extra arguments
      extraArgs: []
    # -- discovery image repository
    imageName: "liqo/discovery"

    config:
      # # -- Set a mnemonic name for your cluster
      # clusterName: cntrl-plane

      # # -- A set of labels which characterizes the local cluster when exposed remotely as a virtual node.
      # # It is suggested to specify the distinguishing characteristics that may be used to decide whether to offload pods on this cluster.
      # clusterLabels: {}
      # # topology.kubernetes.io/zone: us-east-1
      # # liqo.io/provider: your-provider

      # -- Automatically join discovered clusters
      autojoin: true


      # -- Allow (by default) the remote clusters to establish a peering with our cluster
      incomingPeeringEnabled: true

      # -- Enable the mDNS advertisement on LANs, set to false to not be discoverable from other clusters in the same LAN
      enableAdvertisement: false

      # -- Enable the mDNS discovery on LANs, set to false to not look for other clusters available in the same LAN
      enableDiscovery: false

      # -- Time-to-live before an automatically discovered clusters is deleted from the list of available ones if no longer announced (in seconds)
      ttl: 300

  auth:
    pod:
      # -- auth pod annotations
      annotations: {}
      # -- auth pod labels
      labels: {}
      # -- auth pod extra arguments
      extraArgs: []

    # -- auth image repository
    imageName: liqo/auth-service

    initContainer:
      # -- auth init container image repository
      imageName: liqo/cert-creator

    service:
      # -- The type of service used to expose the Authentication Service.
      # If you are exposing this service with an Ingress, you can change it to ClusterIP;
      # if your cluster does not support LoadBalancer services, consider to switch it to NodePort.
      # See https://doc.liqo.io/installation/ for more details.
      type: LoadBalancer
      # -- auth service annotations
      annotations: {}

    # -- Enable TLS for the Authentication Service Pod (using a self-signed certificate).
    # If you are exposing this service with an Ingress consider to disable it or add the appropriate annotations to the Ingress resource.
    tls: true

    # -- Overrides the port where your service is available, you should configure it if behind a NAT or using an Ingress with a port different from 443.
    portOverride: ""

    ingress:
      # -- Auth ingress annotations
      annotations: {}
      # -- Whether to enable the creation of the Ingress resource
      enable: false
      # -- Set the hostname for your ingress
      host: ""
      # -- Set your ingress class
      class: ""

    config:
      # -- Set to false to disable the authentication of discovered clusters. NB: use it only for testing installations
      enableAuthentication: false

  metricAgent:
    # -- Enable the metric agent
    enable: true
    pod:
      # -- metricAgent pod annotations
      annotations: {}
      # -- metricAgent pod labels
      labels: {}
      # -- metricAgent pod extra arguments
      extraArgs: []
    # -- metricAgent image repository
    imageName: "liqo/metric-agent"
    initContainer:
      # -- auth init container image repository
      imageName: "liqo/cert-creator"

  webhook:
    # -- the port the webhook server binds to
    port: 9443
    # -- the webhook failure policy, among Ignore and Fail
    failurePolicy: Fail
    patch:
      # -- the image used for the patch jobs to manage certificates
      image: k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1

  virtualKubelet:
    # -- virtual kubelet image repository
    imageName: liqo/virtual-kubelet

    initContainer:
      # -- virtual kubelet init container image repository
      imageName: liqo/init-virtual-kubelet

    # add additional values for this fields to add to virtual kubelet deployments and pods
    extra:
      # -- virtual kubelet pod extra annotations
      annotations: {}
      # -- virtual kubelet pod extra labels
      labels: {}
      # -- virtual kubelet pod extra arguments
      args: []

    virtualNode:
      extra:
        # -- virtual node extra annotations
        annotations: {}
        # -- virtual node extra labels
        labels: {}

  proxy:
    pod:
      # -- proxy pod annotations
      annotations: {}
      # -- proxy pod labels
      labels: {}
      # -- proxy pod extra arguments
      extraArgs: []

    # -- proxy image repository
    imageName: envoyproxy/envoy:v1.21.0
    
    service:
      type: "ClusterIP"
      annotations: {}
    
    config:
      # -- port used by envoy proxy
      listeningPort: 8118

  storage:
    # -- enable the liqo virtual storage class on the local cluster. You will be able to
    # offload your persistent volumes and other clusters will be able to schedule their
    # persistent workloads on the current cluster.
    enable: true
    # -- name to assign to the liqo virtual storage class
    virtualStorageClassName: liqo
    # -- name of the real storage class to use in the local cluster
    realStorageClassName: ""
    # -- namespace where liqo will deploy specific PVCs
    storageNamespace: liqo-storage

  # -- liqo name override
  nameOverride: ""
  # -- full liqo name override
  fullnameOverride: ""

  # aws configuration for the local cluster and the Liqo user,
  # this user should be able to create new IAM user, to create new programmatic access
  # credentials, and to describe EKS clusters.
  # NOTE: set it only if running on EKS, otherwise let this fields with the default value
  awsConfig:
    # -- accessKeyID for the Liqo user
    accessKeyId: ""
    # -- secretAccessKey for the Liqo user
    secretAccessKey: ""
    # -- AWS region where the clsuter is runnnig
    region: ""
    # -- name of the EKS cluster
    clusterName: ""

  # set the OpenShift-specific configurations
  openshiftConfig:
    # -- enable the OpenShift support
    enable: false
    # -- the security context configurations granted to the virtual kubelet in the local cluster.
    # The configuration of one or more SCCs for the virtual kubelet is not strictly required, and privileges can be reduced in production environments.
    # Still, the default configuration (i.e., anyuid) is suggested to prevent problems (i.e., the virtual kubelet fails to add the appropriate labels) when
    # attempting to offload pods not managed by higher-level abstractions (e.g., Deployments), and not associated with a properly privileged service account.
    # Indeed, "anyuid" is the SCC automatically associated with pods created by cluster administrators.
    # Any pod granted a more privileged SCC and not linked to an adequately privileged service account will fail to be offloaded.
    virtualKubeletSCCs:
      - anyuid

  # configuration for liqo networking
  networkConfig:
    # -- set the mtu for the interfaces managed by liqo: vxlan, tunnel and veth interfaces
    # The value is used by the gateway and route operators.
    # The default value is configured to ensure correct functioning regardless of the combination of the underlying environments
    # (e.g., cloud providers). This guarantees improved compatibility at the cost of possible limited performance drops.
    mtu: 1340

cert-manager:

  fullnameOverride: 'cntrlplane-certmanager'
  # Default values for cert-manager.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.
  global:
    ## Reference to one or more secrets to be used when pulling images
    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
    ##
    imagePullSecrets: []
    # - name: "image-pull-secret"

    # Optional priority class to be used for the cert-manager pods
    priorityClassName: ""

    rbac:
      create: false
      # Aggregate ClusterRoles to Kubernetes default user-facing roles. Ref: https://kubernetes.io/docs/reference/access-authn-authz/rbac/#user-facing-roles
      aggregateClusterRoles: false

    podSecurityPolicy:
      enabled: false
      useAppArmor: true

    # Set the verbosity of cert-manager. Range of 0 - 6 with 6 being the most verbose.
    logLevel: 2

    leaderElection:
      # Override the namespace used to store the ConfigMap for leader election
      namespace: "kube-system"

      # The duration that non-leader candidates will wait after observing a
      # leadership renewal until attempting to acquire leadership of a led but
      # unrenewed leader slot. This is effectively the maximum duration that a
      # leader can be stopped before it is replaced by another candidate.
      # leaseDuration: 60s

      # The interval between attempts by the acting master to renew a leadership
      # slot before it stops leading. This must be less than or equal to the
      # lease duration.
      # renewDeadline: 40s

      # The duration the clients should wait between attempting acquisition and
      # renewal of a leadership.
      # retryPeriod: 15s

  installCRDs: false

  replicaCount: 1

  strategy: {}
    # type: RollingUpdate
    # rollingUpdate:
    #   maxSurge: 0
    #   maxUnavailable: 1

  # Comma separated list of feature gates that should be enabled on the
  # controller pod.
  featureGates: 'AdditionalCertificateOutputFormats=true'

  image:
    repository: quay.io/jetstack/cert-manager-controller
    # You can manage a registry with
    # registry: quay.io
    # repository: jetstack/cert-manager-controller

    # Override the image tag to deploy by setting this variable.
    # If no value is set, the chart's appVersion will be used.
    # tag: canary

    # Setting a digest will override any tag
    # digest: sha256:0e072dddd1f7f8fc8909a2ca6f65e76c5f0d2fcfb8be47935ae3457e8bbceb20
    pullPolicy: IfNotPresent

  # Override the namespace used to store DNS provider credentials etc. for ClusterIssuer
  # resources. By default, the same namespace as cert-manager is deployed within is
  # used. This namespace will not be automatically created by the Helm chart.
  clusterResourceNamespace: ""

  serviceAccount:
    # Specifies whether a service account should be created
    create: false
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    # name: ""
    # Optional additional annotations to add to the controller's ServiceAccount
    # annotations: {}
    # Automount API credentials for a Service Account.
    # Optional additional labels to add to the controller's ServiceAccount
    # labels: {}
    automountServiceAccountToken: false

  # Additional command line flags to pass to cert-manager controller binary.
  # To see all available flags run docker run quay.io/jetstack/cert-manager-controller:<version> --help
  extraArgs:
    - --kubeconfig=/var/run/kubeconfig
    # When this flag is enabled, secrets will be automatically removed when the certificate resource is deleted
    # - --enable-certificate-owner-ref=true
    # Use this flag to enabled or disable arbitrary controllers, for example, disable the CertificiateRequests approver
    # - --controllers=*,-certificaterequests-approver

  extraEnv: []
    # - name: SOME_VAR
    #   value: 'some value'

  resources: {}
    # requests:
    #   cpu: 10m
    #   memory: 32Mi

  # Pod Security Context
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  securityContext:
    runAsNonRoot: true
  # legacy securityContext parameter format: if enabled is set to true, only fsGroup and runAsUser are supported
  # securityContext:
  #   enabled: false
  #   fsGroup: 1001
  #   runAsUser: 1001
  # to support additional securityContext parameters, omit the `enabled` parameter and simply specify the parameters
  # you want to set, e.g.
  # securityContext:
  #   fsGroup: 1000
  #   runAsUser: 1000
  #   runAsNonRoot: true

  # Container Security Context to be set on the controller component container
  # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  containerSecurityContext:
    allowPrivilegeEscalation: false
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true


  volumes:
    - name: kubeconfig
      secret:
        defaultMode: 420
        secretName: infra1-dc1-cntrlplane-kubeconfig

  volumeMounts:
    - mountPath: /var/run/kubeconfig
      name: kubeconfig
      subPath: kubeconfig

  # Optional additional annotations to add to the controller Deployment
  # deploymentAnnotations: {}

  # Optional additional annotations to add to the controller Pods
  # podAnnotations: {}

  podLabels: {}

  # Optional annotations to add to the controller Service
  # serviceAnnotations: {}

  # Optional additional labels to add to the controller Service
  # serviceLabels: {}

  # Optional DNS settings, useful if you have a public and private DNS zone for
  # the same domain on Route 53. What follows is an example of ensuring
  # cert-manager can access an ingress or DNS TXT records at all times.
  # NOTE: This requires Kubernetes 1.10 or `CustomPodDNS` feature gate enabled for
  # the cluster to work.
  # podDnsPolicy: "None"
  # podDnsConfig:
  #   nameservers:
  #     - "1.1.1.1"
  #     - "8.8.8.8"

  nodeSelector:
    kubernetes.io/os: linux

  ingressShim: {}
    # defaultIssuerName: ""
    # defaultIssuerKind: ""
    # defaultIssuerGroup: ""

  prometheus:
    enabled: true
    servicemonitor:
      enabled: false
      prometheusInstance: default
      targetPort: 9402
      path: /metrics
      interval: 60s
      scrapeTimeout: 30s
      labels: {}
      honorLabels: false

  # Use these variables to configure the HTTP_PROXY environment variables
  # http_proxy: "http://proxy:8080"
  # https_proxy: "https://proxy:8080"
  # no_proxy: 127.0.0.1,localhost

  # expects input structure as per specification https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#affinity-v1-core
  # for example:
  #   affinity:
  #     nodeAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        nodeSelectorTerms:
  #        - matchExpressions:
  #          - key: foo.bar.com/role
  #            operator: In
  #            values:
  #            - master
  affinity: {}

  # expects input structure as per specification https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#toleration-v1-core
  # for example:
  #   tolerations:
  #   - key: foo.bar.com/role
  #     operator: Equal
  #     value: master
  #     effect: NoSchedule
  tolerations: []

  webhook:
    replicaCount: 1
    timeoutSeconds: 10

    # Used to configure options for the webhook pod.
    # This allows setting options that'd usually be provided via flags.
    # An APIVersion and Kind must be specified in your values.yaml file.
    # Flags will override options that are set here.
    config:
      # apiVersion: webhook.config.cert-manager.io/v1alpha1
      # kind: WebhookConfiguration

      # The port that the webhook should listen on for requests.
      # In GKE private clusters, by default kubernetes apiservers are allowed to
      # talk to the cluster nodes only on 443 and 10250. so configuring
      # securePort: 10250, will work out of the box without needing to add firewall
      # rules or requiring NET_BIND_SERVICE capabilities to bind port numbers <1000.
      # This should be uncommented and set as a default by the chart once we graduate
      # the apiVersion of WebhookConfiguration past v1alpha1.
      # securePort: 10250

    strategy: {}
      # type: RollingUpdate
      # rollingUpdate:
      #   maxSurge: 0
      #   maxUnavailable: 1

    # Pod Security Context to be set on the webhook component Pod
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    securityContext:
      runAsNonRoot: true

    # Container Security Context to be set on the webhook component container
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    containerSecurityContext:
      allowPrivilegeEscalation: false
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true

    # Optional additional annotations to add to the webhook Deployment
    # deploymentAnnotations: {}

    # Optional additional annotations to add to the webhook Pods
    # podAnnotations: {}

    # Optional additional annotations to add to the webhook Service
    # serviceAnnotations: {}

    # Optional additional annotations to add to the webhook MutatingWebhookConfiguration
    # mutatingWebhookConfigurationAnnotations: {}

    # Optional additional annotations to add to the webhook ValidatingWebhookConfiguration
    # validatingWebhookConfigurationAnnotations: {}

    # Additional command line flags to pass to cert-manager webhook binary.
    # To see all available flags run docker run quay.io/jetstack/cert-manager-webhook:<version> --help
    extraArgs: []
    # Path to a file containing a WebhookConfiguration object used to configure the webhook
    # - --config=<path-to-config-file>

    resources: {}
      # requests:
      #   cpu: 10m
      #   memory: 32Mi

    ## Liveness and readiness probe values
    ## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#container-probes
    ##
    livenessProbe:
      failureThreshold: 3
      initialDelaySeconds: 60
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
    readinessProbe:
      failureThreshold: 3
      initialDelaySeconds: 5
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 1

    nodeSelector:
      kubernetes.io/os: linux

    affinity: {}

    tolerations: []

    # Optional additional labels to add to the Webhook Pods
    podLabels: {}

    # Optional additional labels to add to the Webhook Service
    serviceLabels: {}

    image:
      repository: quay.io/jetstack/cert-manager-webhook
      # You can manage a registry with
      # registry: quay.io
      # repository: jetstack/cert-manager-webhook

      # Override the image tag to deploy by setting this variable.
      # If no value is set, the chart's appVersion will be used.
      # tag: canary

      # Setting a digest will override any tag
      # digest: sha256:0e072dddd1f7f8fc8909a2ca6f65e76c5f0d2fcfb8be47935ae3457e8bbceb20

      pullPolicy: IfNotPresent

    serviceAccount:
      # Specifies whether a service account should be created
      create: false
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      # name: ""
      # Optional additional annotations to add to the controller's ServiceAccount
      # annotations: {}
      # Optional additional labels to add to the webhook's ServiceAccount
      # labels: {}
      # Automount API credentials for a Service Account.
      automountServiceAccountToken: false

    # The port that the webhook should listen on for requests.
    # In GKE private clusters, by default kubernetes apiservers are allowed to
    # talk to the cluster nodes only on 443 and 10250. so configuring
    # securePort: 10250, will work out of the box without needing to add firewall
    # rules or requiring NET_BIND_SERVICE capabilities to bind port numbers <1000
    securePort: 10250

    # Specifies if the webhook should be started in hostNetwork mode.
    #
    # Required for use in some managed kubernetes clusters (such as AWS EKS) with custom
    # CNI (such as calico), because control-plane managed by AWS cannot communicate
    # with pods' IP CIDR and admission webhooks are not working
    #
    # Since the default port for the webhook conflicts with kubelet on the host
    # network, `webhook.securePort` should be changed to an available port if
    # running in hostNetwork mode.
    hostNetwork: false

    # Specifies how the service should be handled. Useful if you want to expose the
    # webhook to outside of the cluster. In some cases, the control plane cannot
    # reach internal services.
    serviceType: ClusterIP
    # loadBalancerIP:

    # Overrides the mutating webhook and validating webhook so they reach the webhook
    # service using the `url` field instead of a service.
    url: {}
      # host:

  cainjector:
    enabled: false
    replicaCount: 1

    strategy: {}
      # type: RollingUpdate
      # rollingUpdate:
      #   maxSurge: 0
      #   maxUnavailable: 1

    # Pod Security Context to be set on the cainjector component Pod
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    securityContext:
      runAsNonRoot: true

    # Container Security Context to be set on the cainjector component container
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    containerSecurityContext:
      allowPrivilegeEscalation: false
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true


    # Optional additional annotations to add to the cainjector Deployment
    # deploymentAnnotations: {}

    # Optional additional annotations to add to the cainjector Pods
    # podAnnotations: {}

    # Additional command line flags to pass to cert-manager cainjector binary.
    # To see all available flags run docker run quay.io/jetstack/cert-manager-cainjector:<version> --help
    extraArgs: []
    # Enable profiling for cainjector
    # - --enable-profiling=true

    resources: {}
      # requests:
      #   cpu: 10m
      #   memory: 32Mi

    nodeSelector:
      kubernetes.io/os: linux

    affinity: {}

    tolerations: []

    # Optional additional labels to add to the CA Injector Pods
    podLabels: {}

    image:
      repository: quay.io/jetstack/cert-manager-cainjector
      # You can manage a registry with
      # registry: quay.io
      # repository: jetstack/cert-manager-cainjector

      # Override the image tag to deploy by setting this variable.
      # If no value is set, the chart's appVersion will be used.
      # tag: canary

      # Setting a digest will override any tag
      # digest: sha256:0e072dddd1f7f8fc8909a2ca6f65e76c5f0d2fcfb8be47935ae3457e8bbceb20

      pullPolicy: IfNotPresent

    serviceAccount:
      # Specifies whether a service account should be created
      create: true
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      # name: ""
      # Optional additional annotations to add to the controller's ServiceAccount
      # annotations: {}
      # Automount API credentials for a Service Account.
      # Optional additional labels to add to the cainjector's ServiceAccount
      # labels: {}
      automountServiceAccountToken: true

  # This startupapicheck is a Helm post-install hook that waits for the webhook
  # endpoints to become available.
  # The check is implemented using a Kubernetes Job- if you are injecting mesh
  # sidecar proxies into cert-manager pods, you probably want to ensure that they
  # are not injected into this Job's pod. Otherwise the installation may time out
  # due to the Job never being completed because the sidecar proxy does not exit.
  # See https://github.com/cert-manager/cert-manager/pull/4414 for context.
  startupapicheck:
    enabled: true

    # Pod Security Context to be set on the startupapicheck component Pod
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    securityContext:
      runAsNonRoot: true

    # Container Security Context to be set on the controller component container
    # ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
    containerSecurityContext:
      allowPrivilegeEscalation: false
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true

    # Timeout for 'kubectl check api' command
    timeout: 1m

    # Job backoffLimit
    backoffLimit: 4

    # Optional additional annotations to add to the startupapicheck Job
    jobAnnotations:
      helm.sh/hook: post-install
      helm.sh/hook-weight: "1"
      helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded

    # Optional additional annotations to add to the startupapicheck Pods
    # podAnnotations: {}

    # Additional command line flags to pass to startupapicheck binary.
    # To see all available flags run docker run quay.io/jetstack/cert-manager-ctl:<version> --help
    extraArgs: []

    resources: {}
      # requests:
      #   cpu: 10m
      #   memory: 32Mi

    nodeSelector: {}

    affinity: {}

    tolerations: []

    # Optional additional labels to add to the startupapicheck Pods
    podLabels: {}

    image:
      repository: quay.io/jetstack/cert-manager-ctl
      # You can manage a registry with
      # registry: quay.io
      # repository: jetstack/cert-manager-ctl

      # Override the image tag to deploy by setting this variable.
      # If no value is set, the chart's appVersion will be used.
      # tag: canary

      # Setting a digest will override any tag
      # digest: sha256:0e072dddd1f7f8fc8909a2ca6f65e76c5f0d2fcfb8be47935ae3457e8bbceb20

      pullPolicy: IfNotPresent

    rbac:
      create: false
      # annotations for the startup API Check job RBAC and PSP resources
      annotations:
        helm.sh/hook: post-install
        helm.sh/hook-weight: "-5"
        helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded

    serviceAccount:
      # Specifies whether a service account should be created
      create: false

      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      # name: ""

      # Optional additional annotations to add to the Job's ServiceAccount
      annotations:
        helm.sh/hook: post-install
        helm.sh/hook-weight: "-5"
        helm.sh/hook-delete-policy: before-hook-creation,hook-succeeded

      # Automount API credentials for a Service Account.
      automountServiceAccountToken: true

      # Optional additional labels to add to the startupapicheck's ServiceAccount
      # labels: {}

external-secrets:
  replicaCount: 1

  image:
    repository: ghcr.io/external-secrets/external-secrets
    pullPolicy: IfNotPresent
    # -- The image tag to use. The default is the chart appVersion.
    tag: ""

  # -- If set, install and upgrade CRDs through helm chart.
  installCRDs: false

  crds:
    # -- If true, create CRDs for Cluster External Secret.
    createClusterExternalSecret: true
    # -- If true, create CRDs for Cluster Secret Store.
    createClusterSecretStore: true

  imagePullSecrets: []
  nameOverride: 'cntrlplane-eso'
  fullnameOverride: ""

  # -- If true, external-secrets will perform leader election between instances to ensure no more
  # than one instance of external-secrets operates at a time.
  leaderElect: false

  # -- If set external secrets will filter matching
  # Secret Stores with the appropriate controller values.
  controllerClass: ""

  # -- If set external secrets are only reconciled in the
  # provided namespace
  scopedNamespace: ""

  # -- Must be used with scopedNamespace. If true, create scoped RBAC roles under the scoped namespace
  # and implicitly disable cluster stores and cluster external secrets
  scopedRBAC: false

  # -- if true, the operator will process cluster external secret. Else, it will ignore them.
  processClusterExternalSecret: true

  # -- if true, the operator will process cluster store. Else, it will ignore them.
  processClusterStore: true

  # -- Specifies whether an external secret operator deployment be created.
  createOperator: true

  # -- Specifies the number of concurrent ExternalSecret Reconciles external-secret executes at
  # a time.
  concurrent: 1

  serviceAccount:
    # -- Specifies whether a service account should be created.
    create: false
    # -- Annotations to add to the service account.
    annotations: {}
    # -- The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template.
    name: ""

  rbac:
    # -- Specifies whether role and rolebinding resources should be created.
    create: false

  ## -- Extra environment variables to add to container.
  extraEnv:
    - name: KUBERNETES_SERVICE_HOST
      value: infra1-dc1-cntrlplane-apiserver.core-prod.svc.cluster.local

    - name: KUBERNETES_SERVICE_PORT
      value: '5443'

    - name: KUBECONFIG
      value: /var/run/kubeconfig

  ## -- Map of extra arguments to pass to container.
  extraArgs: {}

  ## -- Extra volumes to pass to pod.
  extraVolumes:
    - name: kubeconfig
      secret:
        defaultMode: 420
        secretName: infra1-dc1-cntrlplane-kubeconfig

  ## -- Extra volumes to mount to the container.
  extraVolumeMounts:
    - mountPath: /var/run/kubeconfig
      name: kubeconfig
      subPath: kubeconfig

  # -- Annotations to add to Deployment
  deploymentAnnotations: {}

  # -- Annotations to add to Pod
  podAnnotations: {}

  podLabels: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  resources: {}
    # requests:
    #   cpu: 10m
    #   memory: 32Mi

  prometheus:
    # -- deprecated. will be removed with 0.7.0, use serviceMonitor instead.
    enabled: false
    service:
      # -- deprecated. will be removed with 0.7.0, use serviceMonitor instead.
      port: 8080

  serviceMonitor:
    # -- Specifies whether to create a ServiceMonitor resource for collecting Prometheus metrics
    enabled: false

    # -- Additional labels
    additionalLabels: {}

    # --  Interval to scrape metrics
    interval: 30s

    # -- Timeout if metrics can't be retrieved in given time interval
    scrapeTimeout: 25s

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # -- Pod priority class name.
  priorityClassName: ""

  # -- Pod disruption budget - for more details see https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
  podDisruptionBudget:
    enabled: false
    minAvailable: 1
    # maxUnavailable: 1

  webhook:
    # -- Specifies whether a webhook deployment be created.
    create: false
    certCheckInterval: "5m"
    replicaCount: 1
    certDir: /tmp/certs
    # -- specifies whether validating webhooks should be created with failurePolicy: Fail or Ignore
    failurePolicy: Fail
    # -- Specifies if webhook pod should use hostNetwork or not.
    hostNetwork: false
    image:
      repository: ghcr.io/external-secrets/external-secrets
      pullPolicy: IfNotPresent
    # -- The image tag to use. The default is the chart appVersion.
      tag: ""
    imagePullSecrets: []
    nameOverride: ""
    fullnameOverride: ""
    # -- The port the webhook will listen to
    port: 10250
    rbac:
    # -- Specifies whether role and rolebinding resources should be created.
      create: false
    serviceAccount:
      # -- Specifies whether a service account should be created.
      create: false
      # -- Annotations to add to the service account.
      annotations: {}
      # -- The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template.
      name: ""
    nodeSelector: {}

    tolerations: []

    affinity: {}

      # -- Pod priority class name.
    priorityClassName: ""

    # -- Pod disruption budget - for more details see https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
    podDisruptionBudget:
      enabled: false
      minAvailable: 1
      # maxUnavailable: 1
    prometheus:
      # -- deprecated. will be removed with 0.7.0, use serviceMonitor instead
      enabled: false
      service:
        # -- deprecated. will be removed with 0.7.0, use serviceMonitor instead
        port: 8080

    serviceMonitor:
      # -- Specifies whether to create a ServiceMonitor resource for collecting Prometheus metrics
      enabled: false

      # -- Additional labels
      additionalLabels: {}

      # --  Interval to scrape metrics
      interval: 30s

      # -- Timeout if metrics can't be retrieved in given time interval
      scrapeTimeout: 25s

      ## -- Extra environment variables to add to container.
    extraEnv: []

      ## -- Map of extra arguments to pass to container.
    extraArgs: {}

      ## -- Extra volumes to pass to pod.
    extraVolumes: []

      ## -- Extra volumes to mount to the container.
    extraVolumeMounts: []

      # -- Annotations to add to Secret
    secretAnnotations: {}

      # -- Annotations to add to Deployment
    deploymentAnnotations: {}

      # -- Annotations to add to Pod
    podAnnotations: {}

    podLabels: {}

    podSecurityContext: {}
        # fsGroup: 2000

    securityContext: {}
        # capabilities:
        #   drop:
        #   - ALL
        # readOnlyRootFilesystem: true
        # runAsNonRoot: true
        # runAsUser: 1000

    resources: {}
        # requests:
        #   cpu: 10m
        #   memory: 32Mi

  certController:
    # -- Specifies whether a certificate controller deployment be created.
    create: false
    requeueInterval: "5m"
    replicaCount: 1
    image:
      repository: ghcr.io/external-secrets/external-secrets
      pullPolicy: IfNotPresent
      tag: ""
    imagePullSecrets: []
    nameOverride: ""
    fullnameOverride: ""
    rbac:
    # -- Specifies whether role and rolebinding resources should be created.
      create: false

    serviceAccount:
      # -- Specifies whether a service account should be created.
      create: false
      # -- Annotations to add to the service account.
      annotations: {}
      # -- The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template.
      name: ""
    nodeSelector: {}

    tolerations: []

    affinity: {}

      # -- Pod priority class name.
    priorityClassName: ""

    # -- Pod disruption budget - for more details see https://kubernetes.io/docs/concepts/workloads/pods/disruptions/
    podDisruptionBudget:
      enabled: false
      minAvailable: 1
      # maxUnavailable: 1

    prometheus:
      # -- deprecated. will be removed with 0.7.0, use serviceMonitor instead
      enabled: false
      service:
        # -- deprecated. will be removed with 0.7.0, use serviceMonitor instead
        port: 8080

    serviceMonitor:
      # -- Specifies whether to create a ServiceMonitor resource for collecting Prometheus metrics
      enabled: false

      # -- Additional labels
      additionalLabels: {}

      # --  Interval to scrape metrics
      interval: 30s

      # -- Timeout if metrics can't be retrieved in given time interval
      scrapeTimeout: 25s

      ## -- Extra environment variables to add to container.
    extraEnv: []

      ## -- Map of extra arguments to pass to container.
    extraArgs: {}

      ## -- Extra volumes to pass to pod.
    extraVolumes: []

      ## -- Extra volumes to mount to the container.
    extraVolumeMounts: []

      # -- Annotations to add to Deployment
    deploymentAnnotations: {}

      # -- Annotations to add to Pod
    podAnnotations: {}

    podLabels: {}

    podSecurityContext: {}
        # fsGroup: 2000

    securityContext: {}
        # capabilities:
        #   drop:
        #   - ALL
        # readOnlyRootFilesystem: true
        # runAsNonRoot: true
        # runAsUser: 1000

    resources: {}
        # requests:
        #   cpu: 10m
        #   memory: 32Mi
