kubernetes:
  controlPlaneEndpoint:
  networking:
    dnsDomain: cluster.local
    serviceSubnet: 10.0.8.0/22
    podSubnet: 10.4.0.0/16

  persistence:
    enabled: true
    accessModes:
      - ReadWriteOnce
    size: 1Gi
    # storageClassName: default
    annotations: {}
    finalizers:
      - kubernetes.io/pvc-protection

    backup:
      # existingClaim: your-claim
      # subPath: backups
      accessModes:
        - ReadWriteOnce
      size: 1Gi
      # storageClassName: default
      annotations: {}
      finalizers:
        - kubernetes.io/pvc-protection

  etcd:
    enabled: true
    image:
      repository: k8s.gcr.io/etcd
      tag: 3.5.1-0
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      # limits:
      #   cpu: 100m
      #   memory: 128Mi

    certSANs:
      dnsNames: []
      ipAddresses: []

    extraArgs: {}
    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    podAntiAffinity: soft
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    extraEnv: []
    sidecars: []
    extraVolumes: []
    extraVolumeMounts: []

    ports:
      client: 2379
      peer: 2380
      metrics: 2381
    service:
      enabled: true
      type: ClusterIP
      ports:
        client: 2379
        peer: 2380
        metrics: 2381
      labels: {}
      annotations: {}
      loadBalancerIP:

    backup:
      enabled: false
      schedule: "0 */12 * * *"
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 3
      extraArgs: #{}
        debug: true
      resources:
        requests:
          cpu: 100m
          memory: 128Mi
        # limits:
        #   cpu: 100m
        #   memory: 128Mi

      labels: {}
      annotations: {}
      podLabels: {}
      podAnnotations: {}
      nodeSelector: {}
      tolerations: []
      podAffinity: soft
      podAffinityTopologyKey: kubernetes.io/hostname
      affinity: {}
      extraEnv: []
      sidecars: []
      extraVolumes: []
      extraVolumeMounts: []

  apiServer:
    enabled: true
    image:
      repository: k8s.gcr.io/kube-apiserver
      tag: v1.23.6
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      # limits:
      #   cpu: 100m
      #   memory: 128Mi

    certSANs:
      dnsNames: []
      ipAddresses: []

    extraArgs: {}
      # advertise-address is required for kube-proxy
      #advertise-address: 10.9.8.10
    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    podAntiAffinity: soft
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    extraEnv: []
    sidecars: []
    extraVolumes: []
    extraVolumeMounts: []


    port: 6443
    service:
      enabled: true
      type: ClusterIP # NodePort / LoadBalancer
      port: 6443
      # Specify nodePort for apiserver service (30000-32767)
      nodePort:
      labels: {}
      annotations: {}
      loadBalancerIP:

  controllerManager:
    enabled: true
    image:
      repository: k8s.gcr.io/kube-controller-manager
      tag: v1.23.6
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      # limits:
      #   cpu: 100m
      #   memory: 128Mi

    extraArgs: {}
    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    podAntiAffinity: soft
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    extraEnv: []
    sidecars: []
    extraVolumes: []
    extraVolumeMounts: []

    port: 10257
    service:
      enabled: true
      type: ClusterIP
      port: 10257
      labels: {}
      annotations: {}
      loadBalancerIP:

  scheduler:
    enabled: true
    image:
      repository: k8s.gcr.io/kube-scheduler
      tag: v1.23.6
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      # limits:
      #   cpu: 100m
      #   memory: 128Mi

    extraArgs: {}
    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    podAntiAffinity: soft
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    extraEnv: []
    sidecars: []
    extraVolumes: []
    extraVolumeMounts: []

    port: 10259
    service:
      enabled: true
      type: ClusterIP
      port: 10259
      labels: {}
      annotations: {}
      loadBalancerIP:

  admin:
    enabled: true
    image:
      repository: ghcr.io/kvaps/kubernetes-tools
      tag: v0.13.4
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 1
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      # limits:
      #   cpu: 100m
      #   memory: 128Mi

    job:
      enabled: true
      schedule: "0 0 1 */6 *"
      successfulJobsHistoryLimit: 3
      failedJobsHistoryLimit: 3

    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    podAntiAffinity: soft
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    extraEnv: []
    sidecars: []
    extraVolumes: []
    extraVolumeMounts: []

  kubeProxy:
    enabled: true

  coredns:
    enabled: true
    image:
      repository: coredns/coredns
      tag: 1.8.6
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 2
    resources:
      limits:
        memory: 170Mi
      requests:
        cpu: 100m
        memory: 70Mi

  konnectivityServer:
    enabled: false
    # This controls the protocol between the API Server and the Konnectivity server.
    # Supported values are "GRPC" and "HTTPConnect".
    # "GRPC" will deploy konnectivity-server as a sidecar for apiserver
    # "HTTPConnect" will deploy konnectivity-server as separate deployment
    mode: GRPC
    image:
      repository: us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-server
      tag: v0.0.24
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 2
    resources:
      requests:
        cpu: 100m
        memory: 128Mi
      # limits:
      #   cpu: 100m
      #   memory: 128Mi

    extraArgs: {}
    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    podAntiAffinity: soft
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    extraEnv: []
    sidecars: []
    extraVolumes: []
    extraVolumeMounts: []

    ports:
      server: 8131
      agent: 8132
      admin: 8133
      health: 8134
    service:
      enabled: true
      type: ClusterIP
      ports:
        server: 8131
        agent: 8132
        admin: 8133
      nodePorts:
        server:
        agent:
        admin:
      labels: {}
      annotations: {}
      loadBalancerIP:

  konnectivityAgent:
    enabled: false
    image:
      repository: us.gcr.io/k8s-artifacts-prod/kas-network-proxy/proxy-agent
      tag: v0.0.24
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 2
    hostNetwork: true

    extraArgs: {}
    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    podAntiAffinity: soft
    podAntiAffinityTopologyKey: kubernetes.io/hostname
    affinity: {}
    extraEnv: []
    sidecars: []
    extraVolumes: []
    extraVolumeMounts: []

    ports:
      admin: 8133
      health: 8134

  # these manifests will be applied inside the cluster
  extraManifests: {}
    #namespace.yaml:
    #  apiVersion: v1
    #  kind: Namespace
    #  metadata:
    #    name: example

kubefarm:
  # ------------------------------------------------------------------------------
  # Kubernetes control-plane
  # ------------------------------------------------------------------------------
  kubernetes:
    enabled: false
    # See all available options for kubernetes-in-kubernetes chart on:
    # https://github.com/kvaps/kubernetes-in-kubernetes/blob/master/deploy/helm/kubernetes/values.yaml

    persistence:
      enabled: true
      storageClassName: local-path

    apiServer:
      service:
        type: LoadBalancer
        annotations: {}
        loadBalancerIP:

      # Specify external endpoints here to have an oportunity to the Kubernetes cluster externaly
      #certSANs:
      #  ipAddresses:
      #  - 10.9.8.10
      #  dnsNames:
      #  - mycluster.example.org
      #extraArgs:
      #  # advertise-address is required for kube-proxy
      #  advertise-address: 10.9.8.10

  # ------------------------------------------------------------------------------
  # Kubeadm token generator
  # (tokens are needed to join nodes to the cluster)
  # ------------------------------------------------------------------------------
  tokenGenerator:
    enabled: true
    tokenTtl: 24h0m0s
    schedule: "0 */12 * * *"

  # ------------------------------------------------------------------------------
  # Network boot server configuration
  # ------------------------------------------------------------------------------
  ltsp:
    enabled: true
    image:
      repository: ghcr.io/kvaps/kubefarm-ltsp
      tag: v0.13.4
      pullPolicy: IfNotPresent
      pullSecrets: []
    replicaCount: 1

    publishDHCP: true
    service:
      enabled: true
      type: LoadBalancer
      loadBalancerIP:
      labels: {}
      annotations: {}

    labels: {}
    annotations: {}
    podLabels: {}
    podAnnotations: {}
    nodeSelector: {}
    tolerations: []
    affinity: {}
    sidecars: []
    extraVolumes: []

    config:

      # Disable ubuntu apt auto-update task
      disableAutoupdate: true

      # from /usr/share/zoneinfo/<timezone> (eg. Europe/Moscow)
      #timezone: UTC

      # SSH-keys authorized to access the nodes
      sshAuthorizedKeys: []
        #- ssh-rsa AAAAB3N...

      # Hashed password for root, use `openssl passwd -1` to generate one
      #rootPasswd: $1$jaKnTiEb$IhpsNUfssXQ8eQg8orald0 # hackme

      # Sysctl setting for the nodes
      sysctls:
        net.ipv4.ip_forward: 1
        net.ipv6.conf.all.forwarding: 1

      # Modules to load during startup
      modules:
        - br_netfilter
        #- ip_vs
        #- ip_vs_rr
        #- ip_vs_wrr
        #- ip_vs_sh

      # Docker configuration file
      dockerConfig:
        exec-opts: [ native.cgroupdriver=systemd ]
        iptables: false
        ip-forward: false
        bridge: none
        log-driver: journald
        storage-driver: overlay2

      # Extra options for ltsp.conf
      options:
        MENU_TIMEOUT: 0
        #KERNEL_PARAMETERS: "forcepae console=tty1 console=ttyS0,9600n8"

      # Extra sections for ltsp.conf
      sections: {}
        #init/: |
        #  cp -f /etc/ltsp/journald.conf /etc/systemd/journald.conf
        #initrd-bottom/: |
        #  echo "Hello World!"

      # These files will be copied into /etc/ltsp directory for all clients
      # Note: all *.service files will be copied and enabled via systemd
      extraFiles: {}
        #journald.conf: |
        #   [Manager]
        #   SystemMaxUse=200M
        #   RuntimeMaxUse=200M

      # Optionaly you might want to map additional ConfigMaps or Secrets 
      # they will be projected to /etc/ltsp drirectory
      extraProjectedItems: []
        #- secret:
        #    name: ipa-join-token


  # ------------------------------------------------------------------------------
  # Nodes configuration
  # ------------------------------------------------------------------------------
  nodePools:
    -
      # DHCP range for the node pool, required for issuing leases.
      # See --dhcp-range option syntax on dnsmasq-man page.
      # Note: the range will automatically be appended with the set:{{ .Release.Name }}-ltsp option.
      #
      # examples:
      #   172.16.0.0,static,infinite
      #   172.16.0.1,172.16.0.100,255.255.255.0,172.16.0.255,1h
      #
      # WARNING setting broadcast-address is required! (see: https://www.mail-archive.com/dnsmasq-discuss@lists.thekelleys.org.uk/msg14137.html)
      range: ""

      # DHCP configuration for each node
      nodes: []
        #- name: node1
        #  mac: 02:00:ac:10:00:0a
        #  ip: 172.16.0.10

      # Extra tags applied to this node pool, tags may contain additional
      # DHCP- and LTSP- options as well node labels and taints
      tags:
        #- debug
        #- foo

      # Extra Options for Dnsmasq. This section can be used to setup Circuit ID matching.
      # Note: Symbol '?' will automatically be replaced by the '{{ .Release.Name }}-ltsp' tag.
      extraOpts: []
        #- dhcp-circuitid: "set:port_0,ge-0/0/0.0:staging"
        #- dhcp-circuitid: "set:port_1,ge-0/0/1.0:staging"
        #- dhcp-range: "set:?,tag:port_0,192.168.11.10,192.168.11.10,255.255.255.0"
        #- dhcp-range: "set:?,tag:port_1,192.168.11.11,192.168.11.11,255.255.255.0"
        #- tag-if: "set:bar,tag:?,tag:port_0"
        #- tag-if: "set:bar,tag:?,tag:port_1"

  # ------------------------------------------------------------------------------
  # Extra options can be specified for each tag
  # ("all" options are aplicable for any node)
  # ------------------------------------------------------------------------------
  tags:
    dhcpOptions:
      # dnsmasq options
      # see all available options list (https://git.io/JJ0dH)
      all: {}
        #router: 172.16.0.1
        #dns-server: 8.8.8.8
        #broadcast: 172.16.0.255
        #domain-search: infra.example.org

    ltspOptions:
      all:
        FSTAB_KUBELET: "tmpfs /var/lib/kubelet tmpfs x-systemd.wanted-by=kubelet.service 0 0"
        FSTAB_DOCKER: "tmpfs /var/lib/docker tmpfs x-systemd.wanted-by=docker.service 0 0"
        KUBELET_EXTRA_ARGS_CGROUP: "--cgroup-driver=systemd"
      debug:
        DEBUG_SHELL: "1"

    kubernetesLabels:
      all: {}
      #foo:
      #  label1: value1
      #  label2: value2

    kubernetesTaints:
      all: {}
      #foo:
      #  - effect: NoSchedule
      #    key: foo
      #    value: bar

